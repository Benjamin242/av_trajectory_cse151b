{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable \n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "#import seaborn as sns\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean memory\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "### Change to requried path to access data locally, too big too push all data into github\n",
    "#ROOT_PATH = \"C:/Users/Administrator/cse151b-spring2022/argo2/\"\n",
    "ROOT_PATH = \"D:/School/cse151B/argo2/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "\n",
    "        return torch.from_numpy(inputs).float(), torch.from_numpy(outputs).long()\n",
    "\n",
    "    if split==\"test\":\n",
    "    \n",
    "        return torch.from_numpy(inputs).float(), torch.from_numpy(np.array([]))\n",
    "\n",
    "    \n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None, device='cpu'):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "        self.inputs = self.inputs.to(device)\n",
    "        self.outputs = self.outputs.to(device)\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == 'train':\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        if self.split == 'test':\n",
    "            data = self.inputs[idx]\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'palo-alto' \n",
    "split = 'train'\n",
    "train_dataset  = ArgoverseDataset(city = city, split = split, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11993"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset) # current X is 50 in len and Y is 60 in len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.ArgoverseDataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to select proportion of a cities random examples w/o replacement from each city and put all data into one list\n",
    "# purpose: whole dataset is too big and might be redundant\n",
    "def randomCitySampler(prop):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\",\"palo-alto\"]\n",
    "\n",
    "    samples = []\n",
    "    for c in cities:\n",
    "        # get city data\n",
    "        temp_dataset = ArgoverseDataset(city = c, split = \"train\", device=device)\n",
    "\n",
    "        numProp = int(len(temp_dataset) * prop)\n",
    "\n",
    "        # get N number of random indicies\n",
    "        ind = random.sample(range(0, len(temp_dataset)), numProp)\n",
    "        #print(ind)\n",
    "        # push all data indicies into samples list\n",
    "        for i in ind: \n",
    "            samples.append(temp_dataset[i])\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### constants for generating Dataset\n",
    "proportionOfEntireData = 0.2\n",
    "seqLen = 40\n",
    "stepSize = 5\n",
    "batch_sz = 128  # batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40760"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create train dataset, with proportion to actual amount data\n",
    "sampleTest = randomCitySampler(proportionOfEntireData)\n",
    "len(sampleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sequences of length seqLength and specific step size\n",
    "def sequenceGenerator(data, seqLen=40, stepSize=5):\n",
    "    newData = []\n",
    "    for d in data:\n",
    "        # concat X and Y together\n",
    "        temp = torch.cat([d[0],d[1]])\n",
    "        # make X of length SeqLen and Y is next x,y coordinate pair\n",
    "        for i in range(0,len(temp)-seqLen, stepSize):\n",
    "            x = temp[i:i + seqLen]\n",
    "            #flatX = Variable(torch.tensor([item for sublist in x for item in sublist])).to(device)\n",
    "            flatX = torch.flatten(Variable(torch.tensor(x)).to(device))\n",
    "            y = temp[i+seqLen]\n",
    "            newData.append((flatX,y))\n",
    "            \n",
    "        \n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-8e56f7b34fb3>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  flatX = torch.flatten(Variable(torch.tensor(x)).to(device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "570640"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sequences\n",
    "train_seq_data = sequenceGenerator(sampleTest,seqLen, stepSize)\n",
    "len(train_seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([-190.3386, -646.6285, -190.3374, -646.6282, -190.3361, -646.6277,\n",
       "          -190.3349, -646.6282, -190.3335, -646.6281, -190.3322, -646.6283,\n",
       "          -190.3309, -646.6285, -190.3298, -646.6289, -190.3288, -646.6285,\n",
       "          -190.3286, -646.6292, -190.3291, -646.6304, -190.3303, -646.6332,\n",
       "          -190.3321, -646.6367, -190.3340, -646.6390, -190.3366, -646.6422,\n",
       "          -190.3391, -646.6442, -190.3418, -646.6453, -190.3443, -646.6448,\n",
       "          -190.3469, -646.6437, -190.3495, -646.6417, -190.3526, -646.6406,\n",
       "          -190.3557, -646.6402, -190.3584, -646.6381, -190.3614, -646.6367,\n",
       "          -190.3641, -646.6353, -190.3668, -646.6343, -190.3695, -646.6334,\n",
       "          -190.3728, -646.6352, -190.3758, -646.6373, -190.3786, -646.6401,\n",
       "          -190.3815, -646.6432, -190.3838, -646.6456, -190.3864, -646.6494,\n",
       "          -190.3883, -646.6514, -190.3897, -646.6524, -190.3908, -646.6529,\n",
       "          -190.3917, -646.6522, -190.3926, -646.6522, -190.3932, -646.6509,\n",
       "          -190.3936, -646.6491], device='cuda:0'),\n",
       "  tensor([-190.3935, -646.6465], device='cuda:0')),\n",
       " 80)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be a vector of size (80,2) for each example\n",
    "train_seq_data[0], len(train_seq_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loader\n",
    "train_loader = DataLoader(train_seq_data,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, tensor([-190.3935, -646.6465], device='cuda:0'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape is correct\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "len(train_features[0]), train_labels[0]\n",
    "# shape is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "#num_epochs = 60\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = seqLen*2 #number of features\n",
    "hidden_size = 100 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "output_size = 2 #number of output classes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size,num_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size,num_layers)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(num_layers,1,self.hidden_layer_size).to(device),\n",
    "                            torch.zeros(num_layers,1,self.hidden_layer_size).to(device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(80, 100)\n",
       "  (linear): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = LSTM(input_size, hidden_size,output_size,num_layers)\n",
    "lstm = lstm.to(device)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 154246.62500000\n",
      "epoch:   4 loss: 137028.45312500\n",
      "epoch:   7 loss: 319852.68750000\n",
      "epoch:   9 loss: 369894.4375000000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_loader:\n",
    "        lstm.train()\n",
    "        seq = seq.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        lstm.hidden_cell = (torch.zeros(num_layers, 1, lstm.hidden_layer_size).to(device),\n",
    "                        torch.zeros(num_layers, 1, lstm.hidden_layer_size).to(device))\n",
    "        \n",
    "        \n",
    "        y_pred = lstm(seq)\n",
    "        \n",
    "        #print(seq.shape)\n",
    "        #print(y_pred.shape, labels.shape)\n",
    "        #break\n",
    "\n",
    "        loss = loss_function(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%3 == 1:\n",
    "        print(f'epoch: {i:3} loss: {loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to cycle for each test set and use LSTM to predict \n",
    "# add results for each city to dataframe \n",
    "# concatinate all dataframes\n",
    "\n",
    "def validation(model):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\",\"palo-alto\"]\n",
    "\n",
    "    # all the data frames\n",
    "    allDF = []\n",
    "    with torch.no_grad():\n",
    "        for c in cities:\n",
    "            \n",
    "            test_dataset = ArgoverseDataset(city=c, split='test', device=device)\n",
    "            test_loader = DataLoader(test_dataset,batch_size=128)\n",
    "\n",
    "            cityPredictions = []\n",
    "            for t in test_loader.dataset:\n",
    "                model.eval()\n",
    "                flat = torch.flatten(t)\n",
    "                currentPred = []\n",
    "\n",
    "                for i in range(60):\n",
    "                    #print(flat)\n",
    "                    #print(len(flat)-seqLen*2)\n",
    "\n",
    "                    pred = torch.flatten(model(flat[len(flat)-seqLen*2:].view(1,seqLen*2)))\n",
    "\n",
    "                    #print(flat[len(flat)-seqLen*2:].view(1,80))\n",
    "                    #print(pred)\n",
    "\n",
    "                    currentPred.append(pred)\n",
    "\n",
    "                    #print(torch.flatten(pred).shape)\n",
    "                    #print(flat.shape)\n",
    "                    \n",
    "                    flat = torch.cat((flat,pred),0)\n",
    "                    #print(flat)\n",
    "\n",
    "                #print(len(flat[100:]))\n",
    "                cityPredictions.append(flat[100:].detach().to('cpu').numpy())\n",
    "        \n",
    "            df = pd.DataFrame(cityPredictions)\n",
    "            df.columns = ['v' + str(i) for i in (range(120))]\n",
    "            df['ID'] = [str(i) + '_' + c for i in (range(len(test_loader.dataset)))]\n",
    "            allDF.append(df)\n",
    "            \n",
    "    return allDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempValDF = validation(lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tempValDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             0_austin\n",
       "1             1_austin\n",
       "2             2_austin\n",
       "3             3_austin\n",
       "4             4_austin\n",
       "             ...      \n",
       "1681    1681_palo-alto\n",
       "1682    1682_palo-alto\n",
       "1683    1683_palo-alto\n",
       "1684    1684_palo-alto\n",
       "1685    1685_palo-alto\n",
       "Name: ID, Length: 29843, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmPredFinal = pd.concat(tempValDF)\n",
    "lstmPredFinal.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmPredFinal.to_csv(\"lstmbaseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset example size (50,2), prediction should be (1,120)\n",
    "# need to take the last 40 coordinate pairs and reshape to (1,80)\n",
    "# make prediction using LSTM, append that value to test X and repeat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-27c8538712ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mallPredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mflat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcurrentPred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "allPredictions = []\n",
    "for t in test_dataset:\n",
    "    lstm.eval()\n",
    "    flat = torch.flatten(t)\n",
    "    currentPred = []\n",
    "\n",
    "    for i in range(60):\n",
    "        #print(flat)\n",
    "        #print(len(flat)-seqLen*2)\n",
    "\n",
    "        pred = torch.flatten(lstm(flat[len(flat)-seqLen*2:].view(1,80)))\n",
    "\n",
    "        #print(flat[len(flat)-seqLen*2:].view(1,80))\n",
    "        #print(pred)\n",
    "\n",
    "        currentPred.append(pred)\n",
    "\n",
    "        #print(torch.flatten(pred).shape)\n",
    "        #print(flat.shape)\n",
    "        \n",
    "        flat = torch.cat((flat,pred),0)\n",
    "        #print(flat)\n",
    "\n",
    "    #print(len(flat[100:]))\n",
    "    allPredictions.append(flat[100:].detach().to('cpu').numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v110</th>\n",
       "      <th>v111</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v114</th>\n",
       "      <th>v115</th>\n",
       "      <th>v116</th>\n",
       "      <th>v117</th>\n",
       "      <th>v118</th>\n",
       "      <th>v119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>599.000854</td>\n",
       "      <td>1874.806274</td>\n",
       "      <td>599.000854</td>\n",
       "      <td>1874.806274</td>\n",
       "      <td>599.000854</td>\n",
       "      <td>1874.806274</td>\n",
       "      <td>599.000854</td>\n",
       "      <td>1874.806274</td>\n",
       "      <td>599.000854</td>\n",
       "      <td>1874.806274</td>\n",
       "      <td>...</td>\n",
       "      <td>613.276733</td>\n",
       "      <td>1882.481812</td>\n",
       "      <td>613.276733</td>\n",
       "      <td>1882.481812</td>\n",
       "      <td>613.276733</td>\n",
       "      <td>1882.481812</td>\n",
       "      <td>613.276733</td>\n",
       "      <td>1882.481812</td>\n",
       "      <td>613.276733</td>\n",
       "      <td>1882.481812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>963.689331</td>\n",
       "      <td>1406.835571</td>\n",
       "      <td>974.596191</td>\n",
       "      <td>1406.058716</td>\n",
       "      <td>976.589111</td>\n",
       "      <td>1405.352417</td>\n",
       "      <td>976.863770</td>\n",
       "      <td>1405.253540</td>\n",
       "      <td>976.900879</td>\n",
       "      <td>1405.240112</td>\n",
       "      <td>...</td>\n",
       "      <td>1009.284424</td>\n",
       "      <td>1526.676758</td>\n",
       "      <td>1009.284424</td>\n",
       "      <td>1526.676758</td>\n",
       "      <td>1009.284424</td>\n",
       "      <td>1526.676758</td>\n",
       "      <td>1009.284424</td>\n",
       "      <td>1526.676758</td>\n",
       "      <td>1009.284424</td>\n",
       "      <td>1526.676758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-974.396606</td>\n",
       "      <td>2005.361450</td>\n",
       "      <td>-1087.875610</td>\n",
       "      <td>2082.949707</td>\n",
       "      <td>-1116.608276</td>\n",
       "      <td>2102.590088</td>\n",
       "      <td>-1120.982666</td>\n",
       "      <td>2105.580322</td>\n",
       "      <td>-1121.584839</td>\n",
       "      <td>2105.991943</td>\n",
       "      <td>...</td>\n",
       "      <td>-1207.945557</td>\n",
       "      <td>2083.831299</td>\n",
       "      <td>-1207.945557</td>\n",
       "      <td>2083.831299</td>\n",
       "      <td>-1207.945557</td>\n",
       "      <td>2083.831299</td>\n",
       "      <td>-1207.945557</td>\n",
       "      <td>2083.831299</td>\n",
       "      <td>-1207.945557</td>\n",
       "      <td>2083.831299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1256.089722</td>\n",
       "      <td>1845.480347</td>\n",
       "      <td>-1256.089722</td>\n",
       "      <td>1845.480347</td>\n",
       "      <td>-1256.089722</td>\n",
       "      <td>1845.480347</td>\n",
       "      <td>-1256.089722</td>\n",
       "      <td>1845.480347</td>\n",
       "      <td>-1256.089722</td>\n",
       "      <td>1845.480347</td>\n",
       "      <td>...</td>\n",
       "      <td>-1170.249146</td>\n",
       "      <td>1961.452515</td>\n",
       "      <td>-1170.249146</td>\n",
       "      <td>1961.452515</td>\n",
       "      <td>-1210.333984</td>\n",
       "      <td>1976.898315</td>\n",
       "      <td>-1210.787720</td>\n",
       "      <td>1977.073242</td>\n",
       "      <td>-1210.787720</td>\n",
       "      <td>1977.073242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1146.728882</td>\n",
       "      <td>2047.570068</td>\n",
       "      <td>-1147.552979</td>\n",
       "      <td>2049.000244</td>\n",
       "      <td>-1147.666504</td>\n",
       "      <td>2049.197021</td>\n",
       "      <td>-1215.849487</td>\n",
       "      <td>2035.793213</td>\n",
       "      <td>-1215.877075</td>\n",
       "      <td>2035.791870</td>\n",
       "      <td>...</td>\n",
       "      <td>-1210.787720</td>\n",
       "      <td>1977.073242</td>\n",
       "      <td>-1210.787720</td>\n",
       "      <td>1977.073242</td>\n",
       "      <td>-1210.787720</td>\n",
       "      <td>1977.073242</td>\n",
       "      <td>-1210.787720</td>\n",
       "      <td>1977.073242</td>\n",
       "      <td>-1210.787720</td>\n",
       "      <td>1977.073242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            v0           v1           v2           v3           v4  \\\n",
       "0   599.000854  1874.806274   599.000854  1874.806274   599.000854   \n",
       "1   963.689331  1406.835571   974.596191  1406.058716   976.589111   \n",
       "2  -974.396606  2005.361450 -1087.875610  2082.949707 -1116.608276   \n",
       "3 -1256.089722  1845.480347 -1256.089722  1845.480347 -1256.089722   \n",
       "4 -1146.728882  2047.570068 -1147.552979  2049.000244 -1147.666504   \n",
       "\n",
       "            v5           v6           v7           v8           v9  ...  \\\n",
       "0  1874.806274   599.000854  1874.806274   599.000854  1874.806274  ...   \n",
       "1  1405.352417   976.863770  1405.253540   976.900879  1405.240112  ...   \n",
       "2  2102.590088 -1120.982666  2105.580322 -1121.584839  2105.991943  ...   \n",
       "3  1845.480347 -1256.089722  1845.480347 -1256.089722  1845.480347  ...   \n",
       "4  2049.197021 -1215.849487  2035.793213 -1215.877075  2035.791870  ...   \n",
       "\n",
       "          v110         v111         v112         v113         v114  \\\n",
       "0   613.276733  1882.481812   613.276733  1882.481812   613.276733   \n",
       "1  1009.284424  1526.676758  1009.284424  1526.676758  1009.284424   \n",
       "2 -1207.945557  2083.831299 -1207.945557  2083.831299 -1207.945557   \n",
       "3 -1170.249146  1961.452515 -1170.249146  1961.452515 -1210.333984   \n",
       "4 -1210.787720  1977.073242 -1210.787720  1977.073242 -1210.787720   \n",
       "\n",
       "          v115         v116         v117         v118         v119  \n",
       "0  1882.481812   613.276733  1882.481812   613.276733  1882.481812  \n",
       "1  1526.676758  1009.284424  1526.676758  1009.284424  1526.676758  \n",
       "2  2083.831299 -1207.945557  2083.831299 -1207.945557  2083.831299  \n",
       "3  1976.898315 -1210.787720  1977.073242 -1210.787720  1977.073242  \n",
       "4  1977.073242 -1210.787720  1977.073242 -1210.787720  1977.073242  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(allPredictions)\n",
    "df.columns = ['v' + str(i) for i in (range(120))]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM outputs the same value dispite the input being changed???!!\n",
    "TODO: fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 599.0009, 1874.8063]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(Variable(torch.tensor([ 572.8527, 1905.1951,  573.5385, 1904.6764,  574.2172, 1904.1619,\n",
    "          574.8879, 1903.6533,  575.5476, 1903.1481,  576.1949, 1902.6492,\n",
    "          576.8296, 1902.1560,  577.4528, 1901.6644,  578.0621, 1901.1775,\n",
    "          578.6671, 1900.6934,  579.2679, 1900.2146,  579.8611, 1899.7455,\n",
    "          580.4474, 1899.2850,  581.0201, 1898.8361,  581.5807, 1898.3992,\n",
    "          582.1341, 1897.9705,  582.6744, 1897.5505,  583.2040, 1897.1411,\n",
    "          583.7205, 1896.7395,  584.2207, 1896.3500,  584.7043, 1895.9735,\n",
    "          585.1766, 1895.6079,  585.6326, 1895.2549,  586.0690, 1894.9147,\n",
    "          586.4867, 1894.5869,  586.8817, 1894.2736,  587.2586, 1893.9733,\n",
    "          587.6256, 1893.6859,  587.9733, 1893.4167,  588.3030, 1893.1617,\n",
    "          588.6063, 1892.9291,  588.8922, 1892.7115,  589.1613, 1892.5107,\n",
    "          589.4138, 1892.3207,  589.6528, 1892.1404,  589.8758, 1891.9730,\n",
    "          590.0845, 1891.8152,  590.2795, 1891.6677,  590.4625, 1891.5298,\n",
    "          590.6375, 1891.3972])).to(device).view(1,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 599.0009, 1874.8063]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(Variable(torch.tensor([ 574.2172, 1904.1619,  574.8879, 1903.6533,  575.5476, 1903.1481,\n",
    "          576.1949, 1902.6492,  576.8296, 1902.1560,  577.4528, 1901.6644,\n",
    "          578.0621, 1901.1775,  578.6671, 1900.6934,  579.2679, 1900.2146,\n",
    "          579.8611, 1899.7455,  580.4474, 1899.2850,  581.0201, 1898.8361,\n",
    "          581.5807, 1898.3992,  582.1341, 1897.9705,  582.6744, 1897.5505,\n",
    "          583.2040, 1897.1411,  583.7205, 1896.7395,  584.2207, 1896.3500,\n",
    "          584.7043, 1895.9735,  585.1766, 1895.6079,  585.6326, 1895.2549,\n",
    "          586.0690, 1894.9147,  586.4867, 1894.5869,  586.8817, 1894.2736,\n",
    "          587.2586, 1893.9733,  587.6256, 1893.6859,  587.9733, 1893.4167,\n",
    "          588.3030, 1893.1617,  588.6063, 1892.9291,  588.8922, 1892.7115,\n",
    "          589.1613, 1892.5107,  589.4138, 1892.3207,  589.6528, 1892.1404,\n",
    "          589.8758, 1891.9730,  590.0845, 1891.8152,  590.2795, 1891.6677,\n",
    "          590.4625, 1891.5298,  590.6375, 1891.3972,  599.0009, 1874.8063,\n",
    "          599.0009, 1874.8063])).to(device).view(1,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcb3c223ab97c6437cfd6f554c901fa5c15e7f782458399862988fe58f6c8db1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('PytorchVS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
