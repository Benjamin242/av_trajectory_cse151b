{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable \n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "#import seaborn as sns\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# clean memory\\nimport gc\\n\\ngc.collect()\\n\\ntorch.cuda.empty_cache()\\n\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# clean memory\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "### Change to requried path to access data locally, too big too push all data into github\n",
    "#ROOT_PATH = \"C:/Users/Administrator/cse151b-spring2022/argo2/\"\n",
    "ROOT_PATH = \"D:/School/cse151B/argo2/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "\n",
    "        return torch.from_numpy(inputs).float(), torch.from_numpy(outputs).long()\n",
    "\n",
    "    if split==\"test\":\n",
    "    \n",
    "        return torch.from_numpy(inputs).float(), torch.from_numpy(np.array([]))\n",
    "\n",
    "    \n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None, device='cpu'):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "        self.inputs = self.inputs.to(device)\n",
    "        self.outputs = self.outputs.to(device)\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == 'train':\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        if self.split == 'test':\n",
    "            data = self.inputs[idx]\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'palo-alto' \n",
    "split = 'train'\n",
    "#train_dataset  = ArgoverseDataset(city = city, split = split, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to select proportion of a cities random examples w/o replacement from each city and put all data into one list\n",
    "# purpose: whole dataset is too big and might be redundant\n",
    "def randomCitySampler(prop):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\",\"palo-alto\"]\n",
    "\n",
    "    samples = []\n",
    "    for c in cities:\n",
    "        # get city data\n",
    "        temp_dataset = ArgoverseDataset(city = c, split = \"train\", device=device)\n",
    "\n",
    "        numProp = int(len(temp_dataset) * prop)\n",
    "\n",
    "        # get N number of random indicies\n",
    "        ind = random.sample(range(0, len(temp_dataset)), numProp)\n",
    "        #print(ind)\n",
    "        # push all data indicies into samples list\n",
    "        for i in ind: \n",
    "            samples.append(temp_dataset[i])\n",
    "    return samples\n",
    "\n",
    "# generate sequences of length seqLength and specific step size\n",
    "def sequenceGenerator(data, seqLen=40, stepSize=5):\n",
    "    newData = []\n",
    "    for d in data:\n",
    "        # concat X and Y together\n",
    "        temp = torch.cat([d[0],d[1]])\n",
    "        # make X of length SeqLen and Y is next x,y coordinate pair\n",
    "        for i in range(0,len(temp)-seqLen, stepSize):\n",
    "            x = temp[i:i + seqLen]\n",
    "            #flatX = Variable(torch.tensor([item for sublist in x for item in sublist])).to(device)\n",
    "            flatX = torch.flatten(Variable(torch.tensor(x)).to(device))\n",
    "            y = temp[i+seqLen]\n",
    "            newData.append((flatX,y))\n",
    "            \n",
    "        \n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### constants for generating Dataset\n",
    "proportionOfEntireData = 0.001\n",
    "seqLen = 40\n",
    "stepSize = 3\n",
    "batch_sz = 128  # batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train dataset:201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-aa2209eb04b5>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  flatX = torch.flatten(Variable(torch.tensor(x)).to(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of sequences generated:4824\n"
     ]
    }
   ],
   "source": [
    "# create train dataset, with proportion to actual amount data\n",
    "sampleTest = randomCitySampler(proportionOfEntireData)\n",
    "print(\"length of train dataset:\" + str(len(sampleTest)))\n",
    "\n",
    "# generate sequences\n",
    "train_seq_data = sequenceGenerator(sampleTest,seqLen, stepSize)\n",
    "print(\"# of sequences generated:\" + str(len(train_seq_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([-1350.7067, -2750.8108, -1350.3785, -2750.9346, -1349.9807, -2751.0835,\n",
       "          -1349.5171, -2751.2563, -1348.9944, -2751.4519, -1348.4214, -2751.6663,\n",
       "          -1347.8091, -2751.8945, -1347.1722, -2752.1311, -1346.5271, -2752.3699,\n",
       "          -1345.8975, -2752.6016, -1345.3042, -2752.8184, -1344.7107, -2753.0349,\n",
       "          -1344.1135, -2753.2498, -1343.5172, -2753.4646, -1342.9221, -2753.6792,\n",
       "          -1342.3304, -2753.8921, -1341.7388, -2754.1033, -1341.1438, -2754.3135,\n",
       "          -1340.5536, -2754.5222, -1339.9639, -2754.7302, -1339.3729, -2754.9380,\n",
       "          -1338.7805, -2755.1492, -1338.1881, -2755.3596, -1337.5938, -2755.5688,\n",
       "          -1336.9995, -2755.7773, -1336.4041, -2755.9829, -1335.8080, -2756.1851,\n",
       "          -1335.2140, -2756.3811, -1334.6217, -2756.5723, -1334.0299, -2756.7573,\n",
       "          -1333.4473, -2756.9358, -1332.8748, -2757.1094, -1332.3043, -2757.2795,\n",
       "          -1331.7285, -2757.4438, -1331.1555, -2757.6030, -1330.5864, -2757.7568,\n",
       "          -1330.0262, -2757.9033, -1329.4606, -2758.0479, -1328.8873, -2758.1921,\n",
       "          -1328.3088, -2758.3354], device='cuda:0'),\n",
       "  tensor([-1327.7303, -2758.4739], device='cuda:0')),\n",
       " 80)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape check\n",
    "# should be a vector of size (seqlen*2,2) for each example\n",
    "train_seq_data[0], len(train_seq_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loader\n",
    "train_loader = DataLoader(train_seq_data,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, tensor([-1327.7303, -2758.4739], device='cuda:0'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape is correct\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "len(train_features[0]), train_labels[0]\n",
    "# shape is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "input_size_encoder = input_size = seqLen*2 #number of features\n",
    "input_size_decoder = input_size = seqLen*2 #number of features\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 256 #number of features in hidden state\n",
    "num_layers = 2 #number of stacked lstm layers\n",
    "\n",
    "output_size = 2 #number of output classes \n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = 2\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            #best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            #x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 150]\n",
      "tensor([-1327.7303, -2758.4739], device='cuda:0')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-bd9674faa0ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# Forward prop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\PytorchVS\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-c5e2f95c1da6>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, source, target, teacher_force_ratio)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mteacher_force_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mtarget_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtarget_vocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_seq_data):\n",
    "        # Get input and targets and get to cuda\n",
    "        print(batch[1])\n",
    "        inp_data = batch[0].to(device)\n",
    "        target = batch[1].to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target)\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin. While we're at it\n",
    "        # Let's also remove the start token while we're at it\n",
    "        #output = output[1:].reshape(-1, output.shape[2])\n",
    "        #target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Plot to tensorboard\n",
    "        #writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        #step += 1\n",
    "        print(\"Epoch: {0} Loss {1}\".format(epoch,loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to cycle for each test set and use LSTM to predict \n",
    "# add results for each city to dataframe \n",
    "# concatinate all dataframes\n",
    "# returns array of DF for each city formatted for kaggle submission\n",
    "def validation(model):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\",\"palo-alto\"]\n",
    "\n",
    "    # all the data frames\n",
    "    allDF = []\n",
    "    with torch.no_grad():\n",
    "        for c in cities:\n",
    "            \n",
    "            test_dataset = ArgoverseDataset(city=c, split='test', device=device)\n",
    "            test_loader = DataLoader(test_dataset,batch_size=128)\n",
    "\n",
    "            cityPredictions = []\n",
    "            for t in test_loader.dataset:\n",
    "                model.eval()\n",
    "                flat = torch.flatten(t)\n",
    "                currentPred = []\n",
    "\n",
    "                for i in range(60):\n",
    "                    #print(flat)\n",
    "                    #print(len(flat)-seqLen*2)\n",
    "\n",
    "                    pred = torch.flatten(model(flat[len(flat)-seqLen*2:].view(1,seqLen*2)))\n",
    "\n",
    "                    #print(flat[len(flat)-seqLen*2:].view(1,80))\n",
    "                    #print(pred)\n",
    "\n",
    "                    currentPred.append(pred)\n",
    "\n",
    "                    #print(torch.flatten(pred).shape)\n",
    "                    #print(flat.shape)\n",
    "                    \n",
    "                    flat = torch.cat((flat,pred),0)\n",
    "                    #print(flat)\n",
    "\n",
    "                #print(len(flat[100:]))\n",
    "                cityPredictions.append(flat[100:].detach().to('cpu').numpy())\n",
    "        \n",
    "            df = pd.DataFrame(cityPredictions)\n",
    "            df.columns = ['v' + str(i) for i in (range(120))]\n",
    "            df['ID'] = [str(i) + '_' + c for i in (range(len(test_loader.dataset)))]\n",
    "            allDF.append(df)\n",
    "            \n",
    "    return allDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tempValDF = validation(\"model\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcb3c223ab97c6437cfd6f554c901fa5c15e7f782458399862988fe58f6c8db1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('PytorchVS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
