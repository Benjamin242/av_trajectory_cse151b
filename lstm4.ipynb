{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable \n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "#import seaborn as sns\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean memory\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "### Change to requried path to access data locally, too big too push all data into github\n",
    "#ROOT_PATH = \"C:/Users/Administrator/cse151b-spring2022/argo2/\"\n",
    "ROOT_PATH = \"D:/School/cse151B/argo2/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "\n",
    "        return torch.from_numpy(inputs).float(), torch.from_numpy(outputs).long()\n",
    "\n",
    "    if split==\"test\":\n",
    "    \n",
    "        return torch.from_numpy(inputs).float(), torch.from_numpy(np.array([]))\n",
    "\n",
    "    \n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None, device='cpu'):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "        self.inputs = self.inputs.to(device)\n",
    "        self.outputs = self.outputs.to(device)\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == 'train':\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        if self.split == 'test':\n",
    "            data = self.inputs[idx]\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'palo-alto' \n",
    "split = 'train'\n",
    "#train_dataset  = ArgoverseDataset(city = city, split = split, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to select proportion of a cities random examples w/o replacement from each city and put all data into one list\n",
    "# purpose: whole dataset is too big and might be redundant\n",
    "def randomCitySampler(prop,scalingFactor):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\",\"palo-alto\"]\n",
    "\n",
    "    samples = []\n",
    "    for c in cities:\n",
    "        # get city data\n",
    "        temp_dataset = ArgoverseDataset(city = c, split = \"train\", device=device)\n",
    "\n",
    "        numProp = int(len(temp_dataset) * prop)\n",
    "\n",
    "        # get N number of random indicies\n",
    "        ind = random.sample(range(0, len(temp_dataset)), numProp)\n",
    "        #print(ind)\n",
    "        # push all data indicies into samples list\n",
    "        for i in ind: \n",
    "            x = temp_dataset[i][0]/scalingFactor\n",
    "            y = temp_dataset[i][1]/scalingFactor\n",
    "            samples.append((x,y))\n",
    "            \n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### constants for generating Dataset\n",
    "proportionOfEntireData = 0.5\n",
    "seqLen = 40\n",
    "stepSize = 3\n",
    "batch_sz = 64  # batch size \n",
    "scaling_factor = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101906"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create train dataset, with proportion to actual amount data\n",
    "sampleTest = randomCitySampler(proportionOfEntireData,scaling_factor)\n",
    "len(sampleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sequences of length seqLength and specific step size\n",
    "def sequenceGenerator(data, seqLen=40, stepSize=5):\n",
    "    newData = []\n",
    "    for d in data:\n",
    "        # concat X and Y together\n",
    "        temp = torch.cat([d[0],d[1]])\n",
    "        # make X of length SeqLen and Y is next x,y coordinate pair\n",
    "        for i in range(0,len(temp)-seqLen, stepSize):\n",
    "            x = temp[i:i + seqLen]\n",
    "            #flatX = Variable(torch.tensor([item for sublist in x for item in sublist])).to(device)\n",
    "            flatX = torch.flatten(Variable(torch.tensor(x)).to(device))\n",
    "            y = temp[i+seqLen]\n",
    "            newData.append((flatX,y))\n",
    "            \n",
    "        \n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-8e56f7b34fb3>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  flatX = torch.flatten(Variable(torch.tensor(x)).to(device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2445744"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sequences\n",
    "train_seq_data = sequenceGenerator(sampleTest,seqLen, stepSize)\n",
    "len(train_seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([-0.0059,  0.0593, -0.0059,  0.0593, -0.0059,  0.0593, -0.0059,  0.0593,\n",
       "          -0.0060,  0.0594, -0.0060,  0.0594, -0.0061,  0.0594, -0.0061,  0.0594,\n",
       "          -0.0062,  0.0594, -0.0062,  0.0594, -0.0063,  0.0594, -0.0063,  0.0595,\n",
       "          -0.0064,  0.0595, -0.0065,  0.0595, -0.0066,  0.0595, -0.0066,  0.0595,\n",
       "          -0.0067,  0.0596, -0.0068,  0.0596, -0.0069,  0.0596, -0.0070,  0.0596,\n",
       "          -0.0071,  0.0597, -0.0072,  0.0597, -0.0073,  0.0597, -0.0074,  0.0598,\n",
       "          -0.0075,  0.0598, -0.0076,  0.0598, -0.0077,  0.0599, -0.0078,  0.0599,\n",
       "          -0.0079,  0.0599, -0.0080,  0.0600, -0.0081,  0.0600, -0.0083,  0.0601,\n",
       "          -0.0084,  0.0601, -0.0085,  0.0601, -0.0086,  0.0602, -0.0088,  0.0602,\n",
       "          -0.0089,  0.0603, -0.0090,  0.0603, -0.0091,  0.0603, -0.0093,  0.0604],\n",
       "         device='cuda:0'),\n",
       "  tensor([-0.0094,  0.0604], device='cuda:0')),\n",
       " 80)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be a vector of size (80,2) for each example\n",
    "train_seq_data[0], len(train_seq_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loader\n",
    "train_loader = DataLoader(train_seq_data,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, tensor([-0.0094,  0.0604], device='cuda:0'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape is correct\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "len(train_features[0]), train_labels[0]\n",
    "# shape is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "#num_epochs = 60\n",
    "learning_rate = 0.0001\n",
    "\n",
    "input_size = seqLen*2 #number of features\n",
    "hidden_size = 150 #number of features in hidden state\n",
    "num_layers = 2 #number of stacked lstm layers\n",
    "\n",
    "output_size = 2 #number of output classes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size,num_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size,num_layers)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(num_layers,1,self.hidden_layer_size).to(device),\n",
    "                            torch.zeros(num_layers,1,self.hidden_layer_size).to(device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(80, 150, num_layers=2)\n",
       "  (linear): Linear(in_features=150, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = LSTM(input_size, hidden_size,output_size,num_layers)\n",
    "lstm = lstm.to(device)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_loader:\n",
    "        lstm.train()\n",
    "        seq = seq.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        lstm.hidden_cell = (torch.zeros(num_layers, 1, lstm.hidden_layer_size).to(device),\n",
    "                        torch.zeros(num_layers, 1, lstm.hidden_layer_size).to(device))\n",
    "        \n",
    "        \n",
    "        y_pred = lstm(seq)\n",
    "        \n",
    "        #print(seq.shape)\n",
    "        #print(y_pred.shape, labels.shape)\n",
    "        #break\n",
    "\n",
    "        loss = loss_function(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(f'epoch: {i:3} loss: {loss.item():10.8f}')\n",
    "\n",
    "    if i%30 == 0:\n",
    "        modelPath = \"lstm5Epoch{0}.pt\".format(i)\n",
    "        torch.save(lstm.state_dict(), modelPath)\n",
    "\n",
    "print(f'epoch: {i:3} loss: {loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before normailizing:\n",
    "epoch:   0 loss: 1702641.00000000 \\n\n",
    "epoch:  10 loss: 1387110.12500000\\n\n",
    "epoch:  20 loss: 1210237.00000000\\n\n",
    "epoch:  30 loss: 1043616.93750000\\n\n",
    "epoch:  40 loss: 843062.68750000\\n\n",
    "epoch:  50 loss: 642747.50000000\\n\n",
    "epoch:  60 loss: 454254.09375000\\n\n",
    "epoch:  70 loss: 307120.00000000\\n\n",
    "epoch:  80 loss: 195371.10937500\\n\n",
    "epoch:  90 loss: 145173.21875000\\n\n",
    "epoch: 100 loss: 63596.96093750\\n\n",
    "epoch: 110 loss: 32955.25000000\\n\n",
    "epoch: 120 loss: 30699.15625000\\n\n",
    "epoch: 130 loss: 54998.30468750\\n\n",
    "epoch: 140 loss: 54867.91796875\\n\n",
    "epoch: 149 loss: 41005.5078125000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to cycle for each test set and use LSTM to predict \n",
    "# add results for each city to dataframe \n",
    "# concatinate all dataframes\n",
    "\n",
    "def validation(model):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\",\"palo-alto\"]\n",
    "\n",
    "    # all the data frames\n",
    "    allDF = []\n",
    "    with torch.no_grad():\n",
    "        for c in cities:\n",
    "            \n",
    "            test_dataset = ArgoverseDataset(city=c, split='test', device=device)\n",
    "            test_loader = DataLoader(test_dataset,batch_size=128)\n",
    "\n",
    "            cityPredictions = []\n",
    "            for t in test_loader.dataset:\n",
    "                model.eval()\n",
    "                flat = torch.flatten(t)\n",
    "                currentPred = []\n",
    "\n",
    "                for i in range(60):\n",
    "                    #print(flat)\n",
    "                    #print(len(flat)-seqLen*2)\n",
    "\n",
    "                    pred = torch.flatten(model(flat[len(flat)-seqLen*2:].view(1,seqLen*2)))\n",
    "\n",
    "                    #print(flat[len(flat)-seqLen*2:].view(1,80))\n",
    "                    #print(pred)\n",
    "\n",
    "                    currentPred.append(pred)\n",
    "\n",
    "                    #print(torch.flatten(pred).shape)\n",
    "                    #print(flat.shape)\n",
    "                    \n",
    "                    flat = torch.cat((flat,pred),0)\n",
    "                    #print(flat)\n",
    "\n",
    "                #print(len(flat[100:]))\n",
    "                cityPredictions.append(flat[100:].detach().to('cpu').numpy()*scaling_factor)\n",
    "        \n",
    "            df = pd.DataFrame(cityPredictions)\n",
    "            df.columns = ['v' + str(i) for i in (range(120))]\n",
    "            df['ID'] = [str(i) + '_' + c for i in (range(len(test_loader.dataset)))]\n",
    "            allDF.append(df)\n",
    "            \n",
    "    return allDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempValDF = validation(lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tempValDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmPredFinal = pd.concat(tempValDF)\n",
    "lstmPredFinal.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmPredFinal.to_csv(\"lstm5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm.state_dict(), \"lstm5final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MSE: 4022490.07270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcb3c223ab97c6437cfd6f554c901fa5c15e7f782458399862988fe58f6c8db1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('PytorchVS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
