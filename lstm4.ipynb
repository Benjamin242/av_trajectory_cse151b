{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable \n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "#import seaborn as sns\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": null,
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean memory\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060 Ti\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "source": [
    "print(torch.cuda.get_device_name())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": null,
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle5\n",
    "import numpy as np\n",
    "\n",
    "### Change to requried path to access data locally, too big too push all data into github\n",
    "#ROOT_PATH = \"C:/Users/Administrator/cse151b-spring2022/argo2/\"\n",
    "ROOT_PATH = \"C:/Users/Administrator/cse151b-spring2022/argo2/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    inputs = pickle5.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle5.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "\n",
    "        return torch.from_numpy(inputs).float(), torch.from_numpy(outputs).long()\n",
    "\n",
    "    if split==\"test\":\n",
    "    \n",
    "        return torch.from_numpy(inputs).float(), torch.from_numpy(np.array([]))\n",
    "\n",
    "    \n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None, device='cpu'):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "        self.inputs = self.inputs.to(device)\n",
    "        self.outputs = self.outputs.to(device)\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == 'train':\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        if self.split == 'test':\n",
    "            data = self.inputs[idx]\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'palo-alto' \n",
    "split = 'train'\n",
    "#train_dataset  = ArgoverseDataset(city = city, split = split, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": null,
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to select proportion of a cities random examples w/o replacement from each city and put all data into one list\n",
    "# purpose: whole dataset is too big and might be redundant\n",
    "def randomCitySampler(prop):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\",\"palo-alto\"]\n",
    "\n",
    "    samples = []\n",
    "    for c in cities:\n",
    "        # get city data\n",
    "        temp_dataset = ArgoverseDataset(city = c, split = \"train\", device=device)\n",
    "\n",
    "        numProp = int(len(temp_dataset) * prop)\n",
    "\n",
    "        # get N number of random indicies\n",
    "        ind = random.sample(range(0, len(temp_dataset)), numProp)\n",
    "        #print(ind)\n",
    "        # push all data indicies into samples list\n",
    "        for i in ind: \n",
    "            samples.append(temp_dataset[i])\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": null,
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "metadata": {},
   "outputs": [],
   "source": [
    "### constants for generating Dataset\n",
    "proportionOfEntireData = 0.5\n",
    "seqLen = 40\n",
    "stepSize = 3\n",
    "batch_sz = 64  # batch size "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101906"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "source": [
    "# create train dataset, with proportion to actual amount data\n",
    "sampleTest = randomCitySampler(proportionOfEntireData)\n",
    "len(sampleTest)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": null,
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sequences of length seqLength and specific step size\n",
    "def sequenceGenerator(data, seqLen=40, stepSize=5):\n",
    "    newData = []\n",
    "    for d in data:\n",
    "        # concat X and Y together\n",
    "        temp = torch.cat([d[0],d[1]])\n",
    "        # make X of length SeqLen and Y is next x,y coordinate pair\n",
    "        for i in range(0,len(temp)-seqLen, stepSize):\n",
    "            x = temp[i:i + seqLen]\n",
    "            #flatX = Variable(torch.tensor([item for sublist in x for item in sublist])).to(device)\n",
    "            flatX = torch.flatten(Variable(torch.tensor(x)).to(device))\n",
    "            y = temp[i+seqLen]\n",
    "            newData.append((flatX,y))\n",
    "            \n",
    "        \n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\data_analysis\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2445744"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "source": [
    "# generate sequences\n",
    "train_seq_data = sequenceGenerator(sampleTest,seqLen, stepSize)\n",
    "len(train_seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([-327.9885, 1451.2963, -327.9420, 1451.0647, -327.8912, 1450.7791,\n",
       "          -327.8411, 1450.4398, -327.7928, 1450.0465, -327.7450, 1449.6078,\n",
       "          -327.7025, 1449.1268, -327.6707, 1448.6141, -327.6515, 1448.0804,\n",
       "          -327.6456, 1447.5422, -327.6548, 1447.0118, -327.6715, 1446.4707,\n",
       "          -327.6987, 1445.9136, -327.7270, 1445.3430, -327.7598, 1444.7583,\n",
       "          -327.7934, 1444.1548, -327.8308, 1443.5338, -327.8716, 1442.9036,\n",
       "          -327.9132, 1442.2633, -327.9547, 1441.6041, -327.9999, 1440.9294,\n",
       "          -328.0502, 1440.2377, -328.1037, 1439.5306, -328.1594, 1438.8115,\n",
       "          -328.2211, 1438.0780, -328.2880, 1437.3345, -328.3565, 1436.5737,\n",
       "          -328.4236, 1435.8136, -328.4938, 1435.0394, -328.5651, 1434.2638,\n",
       "          -328.6391, 1433.4784, -328.7133, 1432.6855, -328.7883, 1431.8907,\n",
       "          -328.8613, 1431.0979, -328.9352, 1430.3037, -329.0086, 1429.5065,\n",
       "          -329.0855, 1428.6995, -329.1648, 1427.8768, -329.2456, 1427.0419,\n",
       "          -329.3297, 1426.1941], device='cuda:0'),\n",
       "  tensor([-329.4161, 1425.3339], device='cuda:0')),\n",
       " 80)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "outputs": [],
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "source": [
    "# should be a vector of size (80,2) for each example\n",
    "train_seq_data[0], len(train_seq_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loader\n",
    "train_loader = DataLoader(train_seq_data,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, tensor([-329.4161, 1425.3339], device='cuda:0'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "outputs": [],
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "source": [
    "# check shape is correct\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "len(train_features[0]), train_labels[0]\n",
    "# shape is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "#num_epochs = 60\n",
    "learning_rate = 0.00001\n",
    "\n",
    "input_size = seqLen*2 #number of features\n",
    "hidden_size = 150 #number of features in hidden state\n",
    "num_layers = 2 #number of stacked lstm layers\n",
    "\n",
    "output_size = 2 #number of output classes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size,num_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size,num_layers)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(num_layers,1,self.hidden_layer_size).to(device),\n",
    "                            torch.zeros(num_layers,1,self.hidden_layer_size).to(device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(80, 150, num_layers=2)\n",
       "  (linear): Linear(in_features=150, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "outputs": [],
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "source": [
    "lstm = LSTM(input_size, hidden_size,output_size,num_layers)\n",
    "lstm = lstm.to(device)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 1759890.75000000\n",
      "epoch:  10 loss: 1222968.62500000\n",
      "epoch:  20 loss: 941860.50000000\n",
      "epoch:  30 loss: 751587.37500000\n",
      "epoch:  40 loss: 542498.00000000\n",
      "epoch:  50 loss: 352297.09375000\n",
      "epoch:  60 loss: 198653.23437500\n",
      "epoch:  70 loss: 102736.27343750\n",
      "epoch:  80 loss: 51674.44921875\n",
      "epoch:  90 loss: 34824.31250000\n",
      "epoch: 100 loss: 54061.90625000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_19468/88623285.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\data_analysis\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\data_analysis\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "source": [
    "epochs = 150\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_loader:\n",
    "        lstm.train()\n",
    "        seq = seq.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        lstm.hidden_cell = (torch.zeros(num_layers, 1, lstm.hidden_layer_size).to(device),\n",
    "                        torch.zeros(num_layers, 1, lstm.hidden_layer_size).to(device))\n",
    "        \n",
    "        \n",
    "        y_pred = lstm(seq)\n",
    "        \n",
    "        #print(seq.shape)\n",
    "        #print(y_pred.shape, labels.shape)\n",
    "        #break\n",
    "\n",
    "        loss = loss_function(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(f'epoch: {i:3} loss: {loss.item():10.8f}')\n",
    "\n",
    "    if i%30 == 0:\n",
    "        modelPath = \"lstm4Epoch{0}.pt\".format(i)\n",
    "        torch.save(lstm.state_dict(), modelPath)\n",
    "\n",
    "print(f'epoch: {i:3} loss: {loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to cycle for each test set and use LSTM to predict \n",
    "# add results for each city to dataframe \n",
    "# concatinate all dataframes\n",
    "\n",
    "def validation(model):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\",\"palo-alto\"]\n",
    "\n",
    "    # all the data frames\n",
    "    allDF = []\n",
    "    with torch.no_grad():\n",
    "        for c in cities:\n",
    "            \n",
    "            test_dataset = ArgoverseDataset(city=c, split='test', device=device)\n",
    "            test_loader = DataLoader(test_dataset,batch_size=128)\n",
    "\n",
    "            cityPredictions = []\n",
    "            for t in test_loader.dataset:\n",
    "                model.eval()\n",
    "                flat = torch.flatten(t)\n",
    "                currentPred = []\n",
    "\n",
    "                for i in range(60):\n",
    "                    #print(flat)\n",
    "                    #print(len(flat)-seqLen*2)\n",
    "\n",
    "                    pred = torch.flatten(model(flat[len(flat)-seqLen*2:].view(1,seqLen*2)))\n",
    "\n",
    "                    #print(flat[len(flat)-seqLen*2:].view(1,80))\n",
    "                    #print(pred)\n",
    "\n",
    "                    currentPred.append(pred)\n",
    "\n",
    "                    #print(torch.flatten(pred).shape)\n",
    "                    #print(flat.shape)\n",
    "                    \n",
    "                    flat = torch.cat((flat,pred),0)\n",
    "                    #print(flat)\n",
    "\n",
    "                #print(len(flat[100:]))\n",
    "                cityPredictions.append(flat[100:].detach().to('cpu').numpy())\n",
    "        \n",
    "            df = pd.DataFrame(cityPredictions)\n",
    "            df.columns = ['v' + str(i) for i in (range(120))]\n",
    "            df['ID'] = [str(i) + '_' + c for i in (range(len(test_loader.dataset)))]\n",
    "            allDF.append(df)\n",
    "            \n",
    "    return allDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempValDF = validation(lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "outputs": [],
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "source": [
    "len(tempValDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             0_austin\n",
       "1             1_austin\n",
       "2             2_austin\n",
       "3             3_austin\n",
       "4             4_austin\n",
       "             ...      \n",
       "1681    1681_palo-alto\n",
       "1682    1682_palo-alto\n",
       "1683    1683_palo-alto\n",
       "1684    1684_palo-alto\n",
       "1685    1685_palo-alto\n",
       "Name: ID, Length: 29843, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "outputs": [],
>>>>>>> 8c7f3e917913e6cd721f55efa874e05c149ad899
   "source": [
    "lstmPredFinal = pd.concat(tempValDF)\n",
    "lstmPredFinal.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmPredFinal.to_csv(\"lstm4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm.state_dict(), \"lstm4final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81df09b6fc329197c79c0fb00fc4d302ba91ba358ece85a8e43db13ca08453ff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 ('data_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
